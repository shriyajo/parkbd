{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides=pd.read_csv(r\"C:\\Users\\jshri\\OneDrive\\Desktop\\train_peptides.csv\")\n",
    "proteins=pd.read_csv(r\"C:\\Users\\jshri\\OneDrive\\Desktop\\train_proteins.csv\")\n",
    "clinical_data=pd.read_csv(r\"C:\\Users\\jshri\\OneDrive\\Desktop\\train_clinical_data.csv\")\n",
    "supp_clinical=pd.read_csv(r\"C:\\Users\\jshri\\OneDrive\\Desktop\\supplemental_clinical_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(proteins[['visit_id', 'UniProt']].value_counts() == 1)\n",
    "df_p = peptides.merge(proteins[['visit_id', 'UniProt', 'NPX']], on=['visit_id','UniProt'], how='left')\n",
    "df_p.head()\n",
    "#I've rewritten visit_id for supplemental clinical data since it seems that its visit_id was different from convention in other files\n",
    "supp_clinical['visit_id'] = supp_clinical['patient_id'].astype(str) + \"_\"+ supp_clinical['visit_month'].astype(str)\n",
    "\n",
    "#Here we combine both main and supplemental clinical data into a single dataframe\n",
    "df_cd = pd.concat([clinical_data, supp_clinical], ignore_index=True)\n",
    "display(df_cd.info())\n",
    "df_cd.melt(id_vars=['visit_id', 'patient_id', 'visit_month', 'upd23b_clinical_state_on_medication'], \n",
    "                   var_name='updrs', value_name='rating')\n",
    "df_all = df_p.merge(df_cd[['visit_id','updrs_1','updrs_2','updrs_3','updrs_4','upd23b_clinical_state_on_medication']], on=['visit_id'], how='left')\n",
    "df_all.info()\n",
    "df_all['Peptide'].str.extract(r\"(.\\(.*?\\))\", expand=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = df_all\n",
    "# Create a new column that checks whether all UPDRS values are 0\n",
    "df['all_UPDRS_0'] = ((df['updrs_1'] == 0) & (df['updrs_2'] == 0) &\n",
    "                     (df['updrs_3'] == 0) & (df['updrs_4'] == 0))\n",
    "\n",
    "# Group the control patients based on whether all UPDRS values are 0\n",
    "control_groups = df[\n",
    "                    (df['all_UPDRS_0'] == True)]\n",
    "\n",
    "# Print the resulting groups\n",
    "control_groups.head(40)\n",
    "num_patients = control_groups['visit_month'].nunique()\n",
    "print(num_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['updrs_4', 'upd23b_clinical_state_on_medication'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_cutoffs = {'updrs_1': 1.5, 'updrs_2': 5, 'updrs_3': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column indicating whether an individual is less likely to have Parkinson's disease\n",
    "df['no_pd'] = (df_all['updrs_1'] <= updrs_cutoffs['updrs_1']) & (df_all['updrs_2'] <= updrs_cutoffs['updrs_2']) &  (df_all['updrs_3'] <= updrs_cutoffs['updrs_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate no_pd == True (control) and no_pd == False (PD) into different dataframes\n",
    "control_df = df[df['no_pd'] == True]\n",
    "pd_df = df[df['no_pd'] == False]\n",
    "\n",
    "# Drop updrs_4 and all_UPDRS_0 columns\n",
    "control_df = control_df.drop(['updrs_4', 'all_UPDRS_0'], axis=1)\n",
    "pd_df = pd_df.drop(['updrs_4', 'all_UPDRS_0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c648cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = control_df.drop(['visit_id', 'visit_month', 'UniProt', 'NPX','updrs_1', 'updrs_2', 'updrs_3', 'upd23b_clinical_state_on_medication' ,'no_pd'  ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feee3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd_df.drop(['visit_id', 'visit_month', 'UniProt', 'NPX','updrs_1', 'updrs_2', 'updrs_3', 'upd23b_clinical_state_on_medication' ,'no_pd'  ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d1ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9100ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Define a list of hyperparameters to iterate over\n",
    "learning_rates = [0.1, 0.2, 0.5]\n",
    "max_depths = [3, 4, 5]\n",
    "\n",
    "# Initialize an empty dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Separate no_pd == True (control) and no_pd == False (PD) into different dataframes\n",
    "control_df = df[df['no_pd'] == True]\n",
    "pd_df = df[df['no_pd'] == False]\n",
    "control_df.fillna(0, inplace=True)\n",
    "pd_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Drop updrs_4 and all_UPDRS_0 columns\n",
    "control_df = control_df.drop(['updrs_4', 'all_UPDRS_0'], axis=1)\n",
    "pd_df = pd_df.drop(['updrs_4', 'all_UPDRS_0'], axis=1) \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.concat([control_df, pd_df])[['PeptideAbundance']],\n",
    "    pd.concat([control_df, pd_df])['no_pd'].astype(int),\n",
    "    test_size=0.2, \n",
    "    random_state=7)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depths:\n",
    "        model = XGBClassifier(scale_pos_weight=1,\n",
    "                              learning_rate=lr,  \n",
    "                              colsample_bytree = 0.9,\n",
    "                              subsample = 0.3,\n",
    "                              objective='reg:logistic', \n",
    "                              n_estimators=1000, \n",
    "                              reg_alpha = 0.3,\n",
    "                              max_depth=depth, \n",
    "                              gamma=1)\n",
    "        model.fit(X_train,y_train)\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        accuracy_scores[(lr, depth)] = accuracy\n",
    "\n",
    "# Test the model on the testing set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb794d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(X_test, y_test)\n",
    "accuracy_scores[(lr, depth)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Accuracy Scores for Different Hyperparameters\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Max Depth\")\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depths:\n",
    "        score = accuracy_scores[(lr, depth)]\n",
    "        plt.text(lr, depth, \"{:.3f}\".format(score), ha='center', va='center')\n",
    "plt.imshow([[accuracy_scores[(lr, depth)] for depth in max_depths] for lr in learning_rates],\n",
    "           cmap='viridis', interpolation='nearest', origin='lower')\n",
    "plt.xticks(range(len(learning_rates)), learning_rates)\n",
    "plt.yticks(range(len(max_depths)), max_depths)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fd256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Predict classes for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create the classification residual plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_confusion_matrix(model, X_test, y_test, ax=ax, cmap='Blues')\n",
    "ax.set_title(\"Classification Residual Plot\")\n",
    "plot_roc_curve(model, X_test, y_test, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
